# -*- coding: utf-8 -*-
"""camelyon16tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MYQrjVA0EMi5pNf9mGEtbBzGVT6c0661
"""

from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'

# !nvidia-smi

# !apt update && apt install -y openslide-tools
# !pip install openslide-python

# #mount google drive
# from google.colab import drive, files
# drive.mount('/content/drive')

# !ls "/content/drive/My Drive/App_DL_hw2/app_DL_hw2_dataset"

# !ls

# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
from openslide import open_slide, __library_version__ as openslide_version
import os
from PIL import Image
from skimage.color import rgb2gray
# Download an example slide and tumor mask

# Important note: the remainder are in a Google Drive folder, linked above.
# You will need to host them on your own, either in Google Drive, or by using
# the cloud provider of your choice.

tumors = ['001', '002','005','012','016','019','023','031','035','057','059','064','075','078','081','084','091','094','096','101','110']

# for i in tumors:
#   slide = 'tumor_'+i+'.tif'
#   truth = 'tumor_'+i+'_mask.tif'
#   print(slide)
#   print(truth)

slide_path = 'tumor_091.tif'
tumor_mask_path = 'tumor_091_mask.tif'


i = '001'

slide_path = 'tumor_'+i+'.tif'
tumor_mask_path = 'tumor_'+i+'_mask.tif'



import os.path as osp
import openslide
from pathlib import Path

BASE_TRUTH_DIR = Path('/home/jj2883/applied_dl/dataset')

slide_path = str(BASE_TRUTH_DIR / slide_path)
truth_path = str(BASE_TRUTH_DIR / tumor_mask_path)

slide = openslide.open_slide(slide_path)
truth = openslide.open_slide(truth_path)



from skimage.filters import threshold_otsu



from openslide.deepzoom import DeepZoomGenerator 

tiles = DeepZoomGenerator(slide, tile_size=256, overlap=0, limit_bounds=False)
tiles_truth = DeepZoomGenerator(truth, tile_size=256, overlap=0, limit_bounds=False)



def find_patches_from_slide(slide_path, base_truth_dir=BASE_TRUTH_DIR, filter_non_tissue=True):
    """Returns a dataframe of all patches in slide
    input: slide_path: path to WSI file
    output: samples: dataframe with the following columns:
        slide_path: path of slide
        is_tissue: sample contains tissue
        is_tumor: truth status of sample
        tile_loc: coordinates of samples in slide
        
    
    option: base_truth_dir: directory of truth slides
    option: filter_non_tissue: Remove samples no tissue detected
    """
    base_truth_dir = Path(base_truth_dir)
    slide_contains_tumor = slide_path.startswith('tumor_')
    
    #slide_contains_tumor = osp.basename(slide_path).startswith('tumor_')
    
    with openslide.open_slide(slide_path) as slide:
        thumbnail = slide.get_thumbnail((slide.dimensions[0] / 256, slide.dimensions[1] / 256))
    
    thumbnail_grey = np.array(thumbnail.convert('L')) # convert to grayscale
    thresh = threshold_otsu(thumbnail_grey)
    binary = thumbnail_grey > thresh
    
    patches = pd.DataFrame(pd.DataFrame(binary).stack())
    patches['is_tissue'] = ~patches[0]
    patches.drop(0, axis=1, inplace=True)
    patches['slide_path'] = slide_path
    
    if slide_contains_tumor:
        truth_slide_path = osp.basename(slide_path).replace('.tif', '_mask.tif')
#        truth_slide_path = base_truth_dir / osp.basename(slide_path).replace('.tif', '_mask.tif')
        with openslide.open_slide(str(truth_slide_path)) as truth:
            thumbnail_truth = truth.get_thumbnail((truth.dimensions[0] / 256, truth.dimensions[1] / 256)) 
        
        patches_y = pd.DataFrame(pd.DataFrame(np.array(thumbnail_truth.convert("L"))).stack())
        patches_y['is_tumor'] = patches_y[0] > 0
        patches_y.drop(0, axis=1, inplace=True)

        samples = pd.concat([patches, patches_y], axis=1)
    else:
        samples = patches
        samples['is_tumor'] = False
    
    if filter_non_tissue:
        samples = samples[samples.is_tissue == True] # remove patches with no tissue
    samples['tile_loc'] = list(samples.index)
    samples.reset_index(inplace=True, drop=True)
    return samples

all_tissue_samples = find_patches_from_slide(slide_path)
#print('Total patches in slide: %d' % len(all_tissue_samples))
# all_tissue_samples.iloc[:2]
# all_tissue_samples.is_tumor.value_counts()

tumor_samples = all_tissue_samples[all_tissue_samples.is_tumor]
##print(tumor_samples)

import cv2
from keras.utils.np_utils import to_categorical

NUM_CLASSES = 2 # not_tumor, tumor

def gen_imgs(samples, batch_size, base_truth_dir=BASE_TRUTH_DIR, shuffle=True):
    """This function returns a generator that 
    yields tuples of (
        X: tensor, float - [batch_size, 256, 256, 3]
        y: tensor, int32 - [batch_size, 256, 256, NUM_CLASSES]
    )
    
    
    input: samples: samples dataframe
    input: batch_size: The number of images to return for each pull
    output: yield (X_train, y_train): generator of X, y tensors
    
    option: base_truth_dir: path, directory of truth slides
    option: shuffle: bool, if True shuffle samples
    """
    
    num_samples = len(samples)
    while 1: # Loop forever so the generator never terminates
        if shuffle:
            samples = samples.sample(frac=1) # shuffle samples
        
        for offset in range(0, num_samples, batch_size):
            batch_samples = samples.iloc[offset:offset+batch_size]
        
            images = []
            masks = []
            for _, batch_sample in batch_samples.iterrows():
                slide_contains_tumor = osp.basename(batch_sample.slide_path).startswith('tumor_')
                
                with openslide.open_slide(batch_sample.slide_path) as slide:
                    tiles = DeepZoomGenerator(slide, tile_size=256, overlap=0, limit_bounds=False)
                    img = tiles.get_tile(tiles.level_count-1, batch_sample.tile_loc[::-1])



                # only load truth mask for tumor slides
                if slide_contains_tumor:
                    truth_slide_path = base_truth_dir / osp.basename(slide_path).replace('.tif', '_mask.tif')
                    with openslide.open_slide(str(truth_slide_path)) as truth:
                        truth_tiles = DeepZoomGenerator(truth, tile_size=256, overlap=0, limit_bounds=False)
                        mask = truth_tiles.get_tile(truth_tiles.level_count-1, batch_sample.tile_loc[::-1])
                        mask = (cv2.cvtColor(np.array(mask), cv2.COLOR_RGB2GRAY) > 0).astype(int)
                else:
                    mask = np.zeros((256, 256))

                images.append(np.array(img))
                masks.append(mask)

            X_train = np.array(images)
            y_train = np.array(masks)
            y_train = to_categorical(y_train, num_classes=2).reshape(y_train.shape[0], 256, 256, 2)
            yield X_train, y_train

sample_gen = gen_imgs(all_tissue_samples.sample(32, random_state=40), 32, shuffle=False)

tumor_sample_gen = gen_imgs(tumor_samples.sample(32, random_state=15), 32, shuffle=False)

# tumor_samples.sample(32, random_state=15)

# %time example_X, example_y  = next(sample_gen)
# %time example_X, example_y  = next(tumor_sample_gen)

# example_X.shape

# example_y.shape
# example_y[3].shape

# print(example_y[1].shape)


# f, axes = plt.subplots(1, 1, figsize=(20, 10))
# plt.imshow(example_y[1].argmax(axis=2).astype('uint8'),  cmap='gray');
# #axes[0, 0].set_title('Tumor Example');

# example_y[1].argmax(axis=1).shape
# np.amax(example_y[10].argmax(axis=2))
# # print(example_y[1].argmax(axis=2).dtype)

#tumor_sample_gen = gen_imgs(tumor_samples.sample(32, random_state=20), 32, shuffle=False)
# %time example_X, example_y  = next(tumor_sample_gen)



# f, axes = plt.subplots(4, 8, figsize=(20, 10));
# ax = axes.flatten()
# for i in range(0, example_X.shape[0]):
#     _ = ax[i].imshow(example_X[i]);
#     _ = ax[i].axis('off');
# f.suptitle('Batch of Patches 32x256x256x3');
    
# f, axes = plt.subplots(4, 8, figsize=(20, 10));
# ax = axes.flatten()    
# for i in range(0, example_X.shape[0]):
#     _ = ax[i].imshow(example_y[i].argmax(axis=2),  cmap='gray', vmin=0, vmax=1);
#     _ = ax[i].axis('off');
# f.suptitle('Batch of Truth Masks 32x256x256x1');

from keras.models import Sequential
from keras.layers import Lambda, Dropout
from keras.layers.convolutional import Convolution2D, Conv2DTranspose
from keras.layers.pooling import MaxPooling2D

model = Sequential()
model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(256, 256, 3)))
model.add(Convolution2D(100, (5, 5), strides=(2, 2), activation='elu', padding='same'))
model.add(MaxPooling2D())
model.add(Convolution2D(200, (5, 5), strides=(2, 2), activation='elu', padding='same'))
model.add(MaxPooling2D())
model.add(Convolution2D(300, (3, 3), activation='elu', padding='same'))
model.add(Convolution2D(300, (3, 3), activation='elu',  padding='same'))
model.add(Dropout(0.1))
model.add(Convolution2D(2, (1, 1))) # this is called upscore layer for some reason?
model.add(Conv2DTranspose(2, (31, 31), strides=(16, 16), activation='softmax', padding='same'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

BATCH_SIZE = 32
N_EPOCHS = 10

NUM_SAMPLES = 10000

samples = find_patches_from_slide(slide_path)
samples = samples.sample(NUM_SAMPLES, random_state=42)
samples.reset_index(drop=True, inplace=True)

#print(samples)

from sklearn.model_selection import StratifiedShuffleSplit

# split samples into train and validation set
# use StratifiedShuffleSplit to ensure both sets have same proportions of tumor patches
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(samples, samples["is_tumor"]):
        train_samples = samples.loc[train_index]
        validation_samples = samples.loc[test_index]

from datetime import datetime

## TODO Add checkpoint mechanism to save old model before generating new

train_generator = gen_imgs(train_samples, BATCH_SIZE)
validation_generator = gen_imgs(validation_samples, BATCH_SIZE)

# Train model
train_start_time = datetime.now()
model.fit_generator(train_generator, np.ceil(len(train_samples) / BATCH_SIZE),
    validation_data=validation_generator,
    validation_steps=np.ceil(len(validation_samples) / BATCH_SIZE),
    epochs=N_EPOCHS)

train_end_time = datetime.now()
print("Model training time: %.1f minutes" % ((train_end_time - train_start_time).seconds / 60,))

# Save model
model.save('model.h5')

def predict_from_model(patch, model):
    """Predict which pixels are tumor.
    
    input: patch: 256x256x3, rgb image
    input: model: keras model
    output: prediction: 256x256x1, per-pixel tumor probability
    """
    
    prediction = model.predict(patch.reshape(1, 256, 256, 3))
    prediction = prediction[:, :, :, 1].reshape(256, 256)
    return prediction

import matplotlib.gridspec as gridspec

# def plot_blend(patch, prediction, ax, alpha=0.75):
#     """alpha blend patch and prediction.
#     https://matplotlib.org/examples/pylab_examples/layer_images.html
    
#     input: patch: 256x256x3, rgb image
#     input: prediction: 256x256x1, per-pixel tumor probability
#     input: ax: maplotlib Axes object
#     input: alpha: alpha blend
#     """
    
#     dx, dy = 0.05, 0.05
#     x = np.arange(0, patch.shape[1] - 1, dx)
#     y = np.arange(0, patch.shape[0] - 1, dy)
#     xmin, xmax, ymin, ymax = np.amin(x), np.amax(x), np.amin(y), np.amax(y)
#     extent = xmin, xmax, ymin, ymax

#     # fig = plt.figure(frameon=False, figsize=(10, 5))
#     Z1 = cv2.cvtColor(patch, code=cv2.COLOR_RGB2GRAY)
#     Z2 = prediction

#     im1 = ax.imshow(Z1, cmap='gray', extent=extent)
#     im2 = ax.imshow(Z2, cmap='jet', alpha=alpha, vmin=0.0, vmax=1.0,
#                      extent=extent)
#     ax.axis('off');
# def plot_patch_with_pred(patch, truth, prediction, title_str='', alpha=0.6):
#     """
#     input: patch: 256x256x3, rgb image
#     input: truth: 256x256x2, onehot output classes (not_tumor, tumor)
#     input: prediction: 256x256x1, per-pixel tumor probability
#     """
#     gs = gridspec.GridSpec(2, 4, width_ratios=[10, 10, 19, 1])
#     ax0 = plt.subplot(gs[0, 0])
#     ax1 = plt.subplot(gs[0, 1])
#     ax2 = plt.subplot(gs[1, 0])
#     ax3 = plt.subplot(gs[1, 1])
#     ax4 = plt.subplot(gs[:, 2])
#     axc = plt.subplot(gs[:, 3])

#     ax0.imshow(patch);
#     ax0.set_title('Original')
    
#     ax1.imshow(truth.argmax(axis=2), cmap='gray', vmin=0, vmax=1);
#     ax1.set_title('Truth mask (white=tumor, black=not_tumor)')
    
#     p = ax2.imshow(prediction, cmap='jet', vmin=0, vmax=1);
#     ax2.set_title('Prediction heatmap')

#     ax3.imshow((prediction > 0.5).astype(np.int), cmap='gray', vmin=0, vmax=1);
#     ax3.set_title('Prediction mask (white=tumor, black=not_tumor)')
    
#     plot_blend(patch, prediction, ax4, alpha)
#     ax4.set_title('Original+Prediction blend')
    
#     fig = plt.gcf()
#     fig.set_size_inches(20, 10)
#     fig.suptitle(title_str)
#     fig.colorbar(p, cax=axc, orientation="vertical")
#     axc.set_title('Probability pixel is tumor')

# example_patch = example_X[-3]
# example_truth = example_y[-3]

prediction = predict_from_model(example_patch, model)
#plot_patch_with_pred(example_patch, example_truth, prediction, title_str='Example Tumor Patch')

# pred_s = pd.Series(prediction.flatten())
# print(pred_s.describe())
# ax = pred_s.hist(bins=100);
# ax.set_title('Example patch pixel predictions');
# ax.set_ylabel('Count');
# ax.set_xlabel('Probability pixel is tumor');

# example_patch = example_X[16]
# example_truth = example_y[16]

# prediction = predict_from_model(example_patch, model)
# plot_patch_with_pred(example_patch, example_truth, prediction, title_str='Example Tumor Patch')

# pred_s = pd.Series(prediction.flatten())
# print(pred_s.describe())
# ax = pred_s.hist(bins=100);
# ax.set_title('Example patch pixel predictions');
# ax.set_ylabel('Count');
# ax.set_xlabel('Probability pixel is tumor');

# example_patch = example_X[1]
# example_truth = example_y[1]

# prediction = predict_from_model(example_patch, model)
# plot_patch_with_pred(example_patch, example_truth, prediction, title_str='Example Tumor Patch')

# pred_s = pd.Series(prediction.flatten())
# print(pred_s.describe())
# ax = pred_s.hist(bins=100);
# ax.set_title('Example patch pixel predictions');
# ax.set_ylabel('Count');
# ax.set_xlabel('Probability pixel is tumor');

# example_patch = example_X[-13]
# example_truth = example_y[-13]

# prediction = predict_from_model(example_patch, model)
# plot_patch_with_pred(example_patch, example_truth, prediction, title_str='Example Tumor Patch')

# pred_s = pd.Series(prediction.flatten())
# print(pred_s.describe())
# ax = pred_s.hist(bins=100);
# ax.set_title('Example patch pixel predictions');
# ax.set_ylabel('Count');
# ax.set_xlabel('Probability pixel is tumor');

def get_random_patch_from_samples(samples, random_state=None):
    X_i, y_i = next(gen_imgs(samples.sample(1, random_state=random_state), 1))
    return X_i, y_i

X_i, y_i = get_random_patch_from_samples(all_tissue_samples)
pred_i = predict_from_model(X_i, model)
# plot_patch_with_pred(X_i[0], y_i[0], pred_i, title_str='Random Patch')

from sklearn.metrics import confusion_matrix
from tqdm import tqdm

def predict_batch_from_model(patches, model):
    """Predict which pixels are tumor.
    
    input: patch: `batch_size`x256x256x3, rgb image
    input: model: keras model
    output: prediction: 256x256x1, per-pixel tumor probability
    """
    predictions = model.predict(patches)
    predictions = predictions[:, :, :, 1]
    return predictions

validation_generator = gen_imgs(validation_samples, BATCH_SIZE)
validation_steps = np.ceil(len(validation_samples) / BATCH_SIZE)

confusion_mtx = np.zeros((2, 2))

for i in tqdm(range(int(validation_steps))):
    X, y  = next(validation_generator)
    preds = predict_batch_from_model(X, model)
    
    y_true = y[:, :, :, 1].ravel()
    y_pred = np.uint8(preds > 0.5).ravel()
    
    confusion_mtx += confusion_matrix(y_true, y_pred, labels=[0, 1])

confusion_mtx

tn = confusion_mtx[0, 0]
fp = confusion_mtx[0, 1]
fn = confusion_mtx[1, 0]
tp = confusion_mtx[1, 1]

accuracy = (tp + tn) / (tp + tn + fp + fn)
recall = tp / (tp + fn)
precision = tp / (tp + fp)
f1_score = 2 * ((precision * recall) / (precision + recall))

print("Accuracy: %.2f" % accuracy)
print("Recall: %.2f" % recall)
print("Precision: %.2f" % precision)
print("F1 Score: %.2f" % f1_score)

all_samples = find_patches_from_slide(slide_path, filter_non_tissue=False)
print('Total patches in slide: %d' % len(all_samples))
all_samples.iloc[:5]
all_samples.is_tumor.value_counts()

from matplotlib import cm
from tqdm import tqdm

output_dir = Path('/home/jj2883/applied_dl/result')

alpha = 0.5

n_samples = len(all_samples)
n_cols = int(slide.dimensions[0] / 256)
n_rows = int(slide.dimensions[1] / 256)
assert n_cols * n_rows == n_samples

thumbnail = slide.get_thumbnail((n_cols, n_rows))
thumbnail = np.array(thumbnail)

# batch_size = n_cols
batch_size = 32
output_thumbnail_preds = list()
    
for offset in tqdm(list(range(0, n_samples, batch_size))):
    batch_samples = all_samples.iloc[offset:offset+batch_size]
    png_fnames = batch_samples.tile_loc.apply(lambda coord: str(output_dir / ('%d_%d.png' % coord[::-1])))
    
    X, _ = next(gen_imgs(batch_samples, batch_size, shuffle=False))
    
    if batch_samples.is_tissue.nunique() == 1 and batch_samples.iloc[0].is_tissue == False:
        # all patches in this row do not have tissue, skip them all
        output_thumbnail_preds.append(np.zeros(batch_size, dtype=np.float32))
        
        # output pngs
        for i, png_fname in enumerate(png_fnames):
            plt.imsave(png_fname, X[i])
    else:
        # make predictions
        preds = predict_batch_from_model(X, model)
        output_thumbnail_preds.append(preds.mean(axis=(1,2)))

        # overlay preds
        # save blended imgs
        for i, png_fname in enumerate(png_fnames):
            pred_i = preds[i]
            X_i = X[i]
            output_img = cv2.cvtColor(X_i, cv2.COLOR_RGB2GRAY)
            output_img2 = cv2.cvtColor(output_img.copy(), cv2.COLOR_GRAY2RGB)

            overlay = np.uint8(cm.jet(pred_i) * 255)[:,:,:3]
            blended = cv2.addWeighted(overlay, alpha, output_img2, 1-alpha, 0, output_img)
            
            plt.imsave(png_fname, blended)
        

output_thumbnail_preds = np.array(output_thumbnail_preds)

# !cd sample_data; ls

output_thumbnail_preds = output_thumbnail_preds.reshape(n_rows, n_cols)
truth = openslide.open_slide(truth_path)

# f, axes = plt.subplots(1, 2, figsize=(40, 18))
# ax = axes.flatten()
# # plot_blend(thumbnail, output_thumbnail_preds, ax=ax[0])

# thumbnail_truth = truth.get_thumbnail((truth.dimensions[0] / 256, truth.dimensions[1] / 256)) 
# ax[1].imshow(thumbnail_truth.convert('L'), cmap='gray');
# ax[0].set_title('Original+Predictions blend')
# ax[1].set_title('Truth')
# ax[1].axis('off');
# plt.tight_layout();







